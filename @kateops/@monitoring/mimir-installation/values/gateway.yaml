gateway:
  # -- The gateway is deployed by default for enterprise installations (enterprise.enabled=true).
  # Toggle this to have it deployed for non-enterprise installations too.
  enabledNonEnterprise: true

  # -- Number of replicas for the Deployment
  replicas: 1

  # -- HorizontalPodAutoscaler
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 70

  # -- Deployment strategy. See `kubectl explain deployment.spec.strategy` for more,
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  strategy:
    type: RollingUpdate
    # rollingUpdate:
    #   maxSurge: 25%
    #   maxUnavailable: 25%

  # -- The name of the PriorityClass
  priorityClassName: null
  # -- Labels for Deployment Pods
  podLabels: {}
  # -- Annotations Deployment Pods
  podAnnotations: {}
  # -- PodDisruptionBudget https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    maxUnavailable: 1
  # -- Additional CLI args for the container
  extraArgs: {}
  # -- Environment variables to add to the Pods. https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  env: []
  # -- Environment variables from secrets or configmaps to add to the Pods.
  extraEnvFrom: []
  # -- Volumes to add to the Pods
  extraVolumes: []
  # -- Volume mounts to add to the Pods
  extraVolumeMounts: []
  # -- Additional containers to be added to the Pods.
  extraContainers: []
  # - name: dnsmasq
  #   image: "janeczku/go-dnsmasq:release-1.0.7"
  #   imagePullPolicy: IfNotPresent
  #   args:
  #     - --listen
  #     - "127.0.0.1:8053"
  #     - --hostsfile=/etc/hosts
  #     - --enable-search
  #     - --verbose

  # -- Init containers https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  initContainers: []

  # -- SecurityContext override for gateway pods
  securityContext: {}

  # -- The SecurityContext for gateway containers
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop: [ALL]

  # -- Resource requests and limits for the container
  resources:
    requests:
      cpu: 1m
      memory: 13Mi
    limits:
      cpu: 10m
      memory: 20Mi
  # -- Grace period to allow the gateway container to shut down before it is killed
  terminationGracePeriodSeconds: 30

  affinity: {}

  # -- topologySpreadConstraints allows to customize the default topologySpreadConstraints. This can be either a single dict as shown below or a slice of topologySpreadConstraints.
  # labelSelector is taken from the constraint itself (if it exists) or is generated by the chart using the same selectors as for services.
  topologySpreadConstraints:
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway

  # Annotations for the Deployment
  annotations: {}

  # -- Node selector for Deployment Pods
  nodeSelector: {}
  # -- Tolerations for Deployment Pods
  tolerations: []
  # -- Gateway Service configuration
  service:
    # -- Port on which the Service listens
    port: 80
    # -- Type of the Service
    type: ClusterIP
    # -- ClusterIP of the Service
    clusterIP: null
    # -- Node port if service type is NodePort
    nodePort: null
    # -- Load balancer IP address if service type is LoadBalancer
    loadBalancerIP: null
    # -- Annotations for the Service
    annotations: {}
    # -- Labels for the Service
    labels: {}
    # -- DEPRECATED Legacy compatibility port the GEM gateway service listens on, set to 'null' to disable
    legacyPort: 8080
    # -- Overrides the name of the Service. Useful if you are switching from the deprecated nginx or
    # GEM gateway configuration and want to use the same in-cluster address for Mimir/GEM.
    # By using the same name as the nginx/GEM gateway Service, Helm will not delete the Service Resource.
    # Instead, it will update the existing one in place.
    # If left as an empty string, a name is generated.
    nameOverride: ''

  ingress:
    enabled: false
    # -- Overrides the name of the Ingress. Useful if you are switching from the deprecated nginx or
    # GEM gateway configuration and you Ingress Controller needs time to reconcile a new Ingress resource.
    # By using the same name as the nginx/GEM gateway Ingress, Helm will not delete the Ingress Resource.
    # Instead, it will update the existing one in place.
    # If left as an empty string, a name is generated.
    nameOverride: ''
    # -- Ingress Class Name. MAY be required for Kubernetes versions >= 1.18
    ingressClassName: ''
    # -- Annotations for the Ingress
    annotations:
      nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
      nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    # -- Hosts configuration for the nginx ingress
    hosts:
      - host: ${host_domain}
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: mimir-nginx-tls
        hosts:
          - ${host_domain}
  # -- OpenShift Route configuration
  route:
    enabled: false
    # -- Annotations for the Route
    annotations: {}

    host: mimir.example.com

    tls:
      # -- More details about TLS configuration and termination types: https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html#secured-routes
      # For OpenShift 4: https://docs.openshift.com/container-platform/4.11/networking/routes/secured-routes.html
      termination: edge

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 15
    timeoutSeconds: 1

  nginx:
    # -- Enable logging of 2xx and 3xx HTTP requests
    verboseLogging: true

    # -- Image for the nginx. pullPolicy and optional pullSecrets are set in toplevel 'image' section, not here.
    image:
      # -- The Docker registry for nginx image
      registry: docker.io
      # -- The nginx image repository
      repository: nginxinc/nginx-unprivileged
      # -- The nginx image tag
      tag: 1.24-alpine

    # -- Basic auth configuration
    basicAuth:
      # -- Enables basic authentication for nginx
      enabled: false
      # -- The basic auth username for nginx
      username: null
      # -- The basic auth password for nginx
      password: null
      # -- Uses the specified username and password to compute a htpasswd using Sprig's `htpasswd` function.
      # The value is templated using `tpl`. Override this to use a custom htpasswd, e.g. in case the default causes
      # high CPU load.
      htpasswd: >-
        {{ htpasswd (required "'gateway.nginx.basicAuth.username' is required" .Values.gateway.nginx.basicAuth.username) (required "'gateway.nginx.basicAuth.password' is required" .Values.gateway.nginx.basicAuth.password) }}
      # -- Name of an existing basic auth secret to use instead of gateway.nginx.basicAuth.htpasswd. Must contain '.htpasswd' key
      existingSecret: null

    config:
      # -- NGINX log format
      logFormat: |-
        main '$remote_addr - $remote_user [$time_local]  $status '
                '"$request" $body_bytes_sent "$http_referer" '
                '"$http_user_agent" "$http_x_forwarded_for"';
      # -- Sets the log level of the NGINX error log. One of `debug`, `info`, `notice`, `warn`, `error`, `crit`, `alert`, or `emerg`
      errorLogLevel: error
      # -- Enables NGINX access logs
      accessLogEnabled: true
      # -- Allows appending custom configuration to the server block
      serverSnippet: ""
      # -- Allows appending custom configuration to the http block
      httpSnippet: ""
      # -- Allows to set a custom resolver
      resolver: null
      # -- Config file contents for Nginx. Passed through the `tpl` function to allow templating.
      file: |
        worker_processes  5;  ## Default: 1
        error_log  /dev/stderr {{ .Values.gateway.nginx.config.errorLogLevel }};
        pid        /tmp/nginx.pid;
        worker_rlimit_nofile 8192;

        events {
          worker_connections  4096;  ## Default: 1024
        }

        http {
          client_body_temp_path /tmp/client_temp;
          proxy_temp_path       /tmp/proxy_temp_path;
          fastcgi_temp_path     /tmp/fastcgi_temp;
          uwsgi_temp_path       /tmp/uwsgi_temp;
          scgi_temp_path        /tmp/scgi_temp;

          default_type application/octet-stream;
          log_format   {{ .Values.gateway.nginx.config.logFormat }}

          {{- if .Values.gateway.nginx.verboseLogging }}
          access_log   /dev/stderr  main;
          {{- else }}

          map $status $loggable {
            ~^[23]  0;
            default 1;
          }
          access_log   {{ .Values.gateway.nginx.config.accessLogEnabled | ternary "/dev/stderr  main  if=$loggable;" "off;" }}
          {{- end }}

          sendfile     on;
          tcp_nopush   on;

          {{- if .Values.gateway.nginx.config.resolver }}
          resolver {{ .Values.gateway.nginx.config.resolver }};
          {{- else }}
          resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};
          {{- end }}

          {{- with .Values.gateway.nginx.config.httpSnippet }}
          {{ . | nindent 2 }}
          {{- end }}

          # Ensure that X-Scope-OrgID is always present, default to the no_auth_tenant for backwards compatibility when multi-tenancy was turned off.
          map $http_x_scope_orgid $ensured_x_scope_orgid {
            default $http_x_scope_orgid;
            "" "${tenant_ids}";
          }

          proxy_read_timeout 300;
          server {
            listen {{ include "mimir.serverHttpListenPort" . }};

            {{- if .Values.gateway.nginx.basicAuth.enabled }}
            auth_basic           "Mimir";
            auth_basic_user_file /etc/nginx/secrets/.htpasswd;
            {{- end }}

            location = / {
              return 200 'OK';
              auth_basic off;
            }

            location = /ready {
              return 200 'OK';
              auth_basic off;
            }

            proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

            # Distributor endpoints
            location /distributor {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              rewrite ^/distributor(/.*)$ $1 break;
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /api/v1/push {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location /otlp/v1/metrics {
              set $distributor {{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$distributor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Alertmanager endpoints
            location {{ template "mimir.alertmanagerHttpPrefix" . }} {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /multitenant_alertmanager/status {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /api/v1/alerts {
              set $alertmanager {{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$alertmanager:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Ruler endpoints
            location /config/v1/rules {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location /api/v1/rules {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            location /api/v1/alerts {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }
            location = /ruler/ring {
              set $ruler {{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$ruler:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Rest of {{ template "mimir.prometheusHttpPrefix" . }} goes to the query frontend
            location / {
              set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}{{ template "mimir.prometheusHttpPrefix" . }}$request_uri;
            }

            #location /api/v1/targets {
            #  set $agent 10-1-53-90.monitoring.pod.cluster.local:8080;
            #  proxy_pass http://$agent/agent/api/v1/metrics/targets;
            #}
  
            # Buildinfo endpoint can go to any component
            location = /api/v1/status/buildinfo {
              set $query_frontend {{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$query_frontend:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            # Compactor endpoint for uploading blocks
            location /api/v1/upload/block/ {
              set $compactor {{ template "mimir.fullname" . }}-compactor.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }};
              proxy_pass      http://$compactor:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
            }

            {{- with .Values.nginx.nginxConfig.serverSnippet }}
            {{ . | nindent 4 }}
            {{- end }}
          }
        }